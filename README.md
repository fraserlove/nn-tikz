# NNTikZ

A collection of TikZ diagrams for neural network and deep learning concepts. This repository was created to provide a set of open-source diagrams for use in academic papers and presentations.

If you use this repository in your research or project, please cite it as follows:
```
@misc{love2024nntikz,
    author = {Fraser Love},
    title = {NNTikZ - TikZ Diagrams for Deep Learning and Neural Networks},
    year = 2024,
    url = {https://github.com/fraserlove/nntikz},
    note = {GitHub repository}
}
```

See some examples below:

#### Transformer - [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762)
<img src="assets/transformer.png" alt="Transformer" width="400"/>

#### Multi-Head Attention - [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762)
<img src="assets/multihead_attention.png" alt="Multi-Head Attention" width="400"/>

#### Neural Network
<img src="assets/neural_network.png" alt="Neural Network" width="400"/>

#### Attention Mechanism - [Bahdanau et al. (2014)](https://arxiv.org/abs/1409.0473)
<img src="assets/attention.png" alt="Attention Mechanism" width="400"/>

#### Gated Recurrent Unit (GRU) - [Cho et al. (2014)](https://arxiv.org/abs/1406.1078)
<img src="assets/gru.png" alt="GRU" width="400"/>

#### RNN Encoder-Decoder - [Sutskever et al. (2014)](https://arxiv.org/abs/1409.3215)
<img src="assets/rnn_encoder_decoder_sutskever.png" alt="RNN Encoder-Decoder" width="400"/>

#### Backpropagation Through Time (BPTT) - [Werbos (1990)](https://www.researchgate.net/publication/220365479_Backpropagation_through_time)
<img src="assets/rnn_backprop.png" alt="BPTT" width="400"/>
